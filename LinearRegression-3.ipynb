{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jB0cT3ONNanp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "from numpy.linalg import inv\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "from numpy.linalg import pinv\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_LinRegr(X_train, y_train):\n",
        "\n",
        "  # Add a column of ones to X_train for the bias term\n",
        "  X_train = np.hstack((np.ones((X_train.shape[0], 1)), X_train))\n",
        "\n",
        "  # Applying the minimizer to find the best-fit weights\n",
        "  # w = (X^T * X)^-1 * X^T * y\n",
        "  w = pinv(X_train.T.dot(X_train)).dot(X_train.T).dot(y_train)\n",
        "\n",
        "  return w\n"
      ],
      "metadata": {
        "id": "N8GKRuPycCAy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mse(X, y, w):\n",
        "\n",
        "  # Predict the values using the weights w\n",
        "  predictions = pred(X, w)\n",
        "  # Compute the mean squared error between the predicted and actual values\n",
        "  avgError = np.mean((predictions - y) ** 2)\n",
        "\n",
        "  return avgError\n"
      ],
      "metadata": {
        "id": "xo_yKyNkcOoX"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pred(X_train, w):\n",
        "\n",
        "  # Add a column of ones to X_train for the bias term\n",
        "  X_train = np.hstack((np.ones((X_train.shape[0], 1)), X_train))\n",
        "  # Compute the predictions: y_pred = X * w\n",
        "  predictions = X_train.dot(w)\n",
        "\n",
        "  return predictions"
      ],
      "metadata": {
        "id": "8svrcvoccWxw"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_SciKit(X_train, X_test, Y_train, Y_test):\n",
        "\n",
        "  # Initialize the linear regression model\n",
        "  LR = LinearRegression()\n",
        "\n",
        "  # Fit the model on the training data\n",
        "  LR.fit(X_train, Y_train)\n",
        "\n",
        "  # Predict the target values for the test set\n",
        "  Y_pred = LR.predict(X_test)\n",
        "\n",
        "  # Calculate the mean squared error using the true and predicted values\n",
        "  error = mean_squared_error(Y_test, Y_pred)\n",
        "\n",
        "  return error"
      ],
      "metadata": {
        "id": "hA4ueShocYGp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def subtestFn():\n",
        "    # This function tests if your solution is robust against singular matrix\n",
        "\n",
        "    # X_train has two perfectly correlated features\n",
        "    X_train = np.asarray([[1, 2], [2, 4], [3, 6], [4, 8]])\n",
        "    y_train = np.asarray([1,2,3,4])\n",
        "\n",
        "    try:\n",
        "      w=fit_LinRegr(X_train, y_train)\n",
        "      print (\"weights: \", w)\n",
        "      print (\"NO ERROR\")\n",
        "    except:\n",
        "      print (\"ERROR\")\n",
        "\n",
        "def testFn_Part2():\n",
        "    X_train, y_train = load_diabetes(return_X_y=True)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_train,y_train,test_size=0.2)\n",
        "\n",
        "    w=fit_LinRegr(X_train, y_train)\n",
        "\n",
        "    #Testing Part 2a\n",
        "    e=mse(X_test,y_test,w)\n",
        "\n",
        "    #Testing Part 2b\n",
        "    scikit=test_SciKit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "    print(\"Mean squared error from Part 2a is \", e)\n",
        "    print(\"Mean squared error from Part 2b is \", scikit)\n",
        "\n",
        "print ('------------------subtestFn----------------------')\n",
        "subtestFn()\n",
        "\n",
        "print ('------------------testFn_Part2-------------------')\n",
        "testFn_Part2()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-rnd0rAQR4b",
        "outputId": "a65f96af-78fa-4c46-d80c-54685e1031ce"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------subtestFn----------------------\n",
            "weights:  [1.04360964e-14 2.00000000e-01 4.00000000e-01]\n",
            "NO ERROR\n",
            "------------------testFn_Part2-------------------\n",
            "Mean squared error from Part 2a is  2775.633903843639\n",
            "Mean squared error from Part 2b is  2775.6339038436495\n"
          ]
        }
      ]
    }
  ]
}