{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ji9oP34yP0XF"
      },
      "outputs": [],
      "source": [
        "#NumPy for Matrix Computation\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#Train Test split for shuffling the data and splits it\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import Perceptron\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def pred(X_i, w):\n",
        "  # Function to make predictions using the perceptron model\n",
        "  class_label = 1 if np.dot(X_i, w) > 0 else -1\n",
        "\n",
        "  return class_label\n",
        "\n",
        "def errorPer(X_train, y_train, w):\n",
        "\n",
        "  # Add a column of ones to X_train for the bias term if not already included\n",
        "  if X_train.shape[1] != w.shape[0]:\n",
        "    X_train = np.hstack((np.ones((X_train.shape[0], 1)), X_train))\n",
        "\n",
        "  # Initialize the error count\n",
        "  errors = 0\n",
        "\n",
        "  # Loop through all training samples\n",
        "  for i in range(len(X_train)):\n",
        "    # Predict class label for each sample\n",
        "    predicted = pred(X_train[i], w)\n",
        "\n",
        "    # Check if prediction is incorrect\n",
        "    if predicted != y_train[i]:\n",
        "      errors += 1\n",
        "\n",
        "  # Calculate the average number of misclassifications\n",
        "  avgError = errors / len(X_train)\n",
        "\n",
        "  return avgError"
      ],
      "metadata": {
        "id": "yVl6KiBmc5eE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_Perceptron(X_train, y_train):\n",
        "\n",
        "  max_epochs = 5000\n",
        "  # Add a column of ones to X_train for the bias term\n",
        "  X_train = np.hstack((np.ones((X_train.shape[0], 1)), X_train))\n",
        "\n",
        "  # Initialize weights to zero\n",
        "  w = np.zeros(X_train.shape[1])\n",
        "  pocket_w = np.copy(w)\n",
        "  pocket_error = errorPer(X_train, y_train, w)\n",
        "\n",
        "  # Main loop to fit the data\n",
        "  for j in range(max_epochs):\n",
        "    for i in range(X_train.shape[0]):\n",
        "      # Check if the current sample is misclassified\n",
        "      if y_train[i] * np.dot(X_train[i], w) <= 0:\n",
        "        # Update weights\n",
        "        w += y_train[i] * X_train[i]\n",
        "\n",
        "        # Calculate error with the updated weights\n",
        "        current_error = errorPer(X_train, y_train, w)\n",
        "        # If the updated weights have a lower error, update the pocket weights\n",
        "        if current_error < pocket_error:\n",
        "          pocket_w = np.copy(w)\n",
        "          pocket_error = current_error\n",
        "  # Return the best weights from the pocket\n",
        "  return pocket_w\n",
        "\n"
      ],
      "metadata": {
        "id": "JcAv7UgQc0KO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def confMatrix(X_train, y_train, w):\n",
        "\n",
        "  # Initialize the confusion matrix\n",
        "  confusion_matrix = np.array([[0, 0], [0, 0]])\n",
        "\n",
        "  # Add a column of ones to X_train for the bias term if not already included\n",
        "  if X_train.shape[1] != w.shape[0]:\n",
        "    X_train = np.hstack((np.ones((X_train.shape[0], 1)), X_train))\n",
        "\n",
        "  # Loop through all training samples\n",
        "  for i in range(len(X_train)):\n",
        "    # Predict class label for each sample\n",
        "    prediction = pred(X_train[i], w)\n",
        "\n",
        "    # Update confusion matrix based on predictions\n",
        "    if prediction == 1 and y_train[i] == 1:\n",
        "      confusion_matrix[1][1] += 1  # True Positive\n",
        "    elif prediction == 1 and y_train[i] == -1:\n",
        "      confusion_matrix[0][1] += 1  # False Positive\n",
        "    elif prediction == -1 and y_train[i] == -1:\n",
        "      confusion_matrix[0][0] += 1  # True Negative\n",
        "    elif prediction == -1 and y_train[i] == 1:\n",
        "      confusion_matrix[1][0] += 1  # False Negative\n",
        "\n",
        "  return confusion_matrix\n"
      ],
      "metadata": {
        "id": "HBwRat4RdR6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_SciKit(X_train, X_test, Y_train, Y_test):\n",
        "\n",
        "  # Initialize the Perceptron classifier\n",
        "  clf = Perceptron(tol=1e-3, random_state=0)\n",
        "\n",
        "  # Fit the Perceptron classifier on the training data\n",
        "  clf.fit(X_train, Y_train)\n",
        "\n",
        "  # Make predictions on the test data\n",
        "  Y_pred = clf.predict(X_test)\n",
        "\n",
        "  # Compute the confusion matrix between the true test labels and predictions\n",
        "  conf_matrix = confusion_matrix(Y_test, Y_pred, labels=np.unique(Y_train))\n",
        "\n",
        "  return conf_matrix"
      ],
      "metadata": {
        "id": "GcPXYgmuebyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_Part1():\n",
        "    from sklearn.datasets import load_iris\n",
        "    X_train, y_train = load_iris(return_X_y=True)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_train[50:],y_train[50:],test_size=0.2)\n",
        "\n",
        "    #Set the labels to +1 and -1\n",
        "    y_train[y_train == 1] = 1\n",
        "    y_train[y_train != 1] = -1\n",
        "    y_test[y_test == 1] = 1\n",
        "    y_test[y_test != 1] = -1\n",
        "\n",
        "    #Pocket algorithm using Numpy\n",
        "    w=fit_Perceptron(X_train,y_train)\n",
        "    cM=confMatrix(X_test,y_test,w)\n",
        "\n",
        "    #Pocket algorithm using scikit-learn\n",
        "    sciKit=test_SciKit(X_train, X_test, y_train, y_test)\n",
        "\n",
        "    #Print the result\n",
        "    print ('--------------Test Result-------------------')\n",
        "    print(\"Confusion Matrix is from Part 1a is: \",cM)\n",
        "    print(\"Confusion Matrix from Part 1b is:\",sciKit)\n",
        "\n",
        "test_Part1()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFwDp00Xdkwa",
        "outputId": "e61df78d-a0c8-4cb8-dd9a-38e66ccbe443"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------Test Result-------------------\n",
            "Confusion Matrix is from Part 1a is:  [[12  0]\n",
            " [ 0  8]]\n",
            "Confusion Matrix from Part 1b is: [[12  0]\n",
            " [ 0  8]]\n"
          ]
        }
      ]
    }
  ]
}